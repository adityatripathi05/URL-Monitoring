# Global Agent Configuration
[agent]
  interval = "10s"
  round_interval = true
  metric_batch_size = 1000
  metric_buffer_limit = 10000
  collection_jitter = "0s"
  flush_interval = "10s"
  flush_jitter = "0s"
  precision = ""
  hostname = ""
  omit_hostname = false

# Input Plugin: HTTP Response Monitoring
# TODO: Configure dynamic URL fetching from FastAPI backend
# Option 1: Use inputs.execd or inputs.exec to fetch URLs and write to a file, then use urls_from_file here.
# Option 2: Fetch a dynamic config snippet using inputs.http.
[[inputs.http_response]]
  ## List of URLs to query.
  urls = [
    "https://example.com", # Placeholder URL
    "https://google.com"   # Placeholder URL
  ]

  ## Set response_timeout (default 5 seconds)
  response_timeout = "5s"

  ## HTTP method (default: "GET")
  method = "GET"

  ## Optional HTTP headers
  # headers = {"X-Special-Header" = "Telegraf"}

  ## Optional body for POST/PUT requests
  # body = ""

  ## Optional follow redirects (default: false)
  follow_redirects = true

  ## Optional skip TLS verification (default: false)
  # insecure_skip_verify = true

  ## Tags to add to measurements
  [inputs.http_response.tags]
    source = "telegraf"

# Output Plugin: PostgreSQL / TimescaleDB
[[outputs.postgresql]]
  ## Connection string for TimescaleDB
  ## Example: "host=timescaledb user=postgres password=password dbname=url_monitoring sslmode=disable"
  ## Using environment variables for security
  connection = "host=${POSTGRES_HOST} port=${POSTGRES_PORT} user=${POSTGRES_USER} password=${POSTGRES_PASSWORD} dbname=${POSTGRES_DB} sslmode=disable"

  ## Schema to use (default: "public")
  # schema = "public"

  ## Table name for metrics (default: based on measurement name)
  # table_template = "CREATE TABLE IF NOT EXISTS {TABLE}({COLUMNS})"

  ## Enable tags as JSONB column (default: false)
  tags_as_foreign_keys = false # Keep tags in separate columns if possible for TimescaleDB performance
  tags_as_jsonb = false

  ## Enable fields as JSONB column (default: false)
  # fields_as_jsonb = false

  ## Specify how to handle existing tables (create, append, drop)
  # table_exists_action = "create"

  ## Number of rows to buffer before writing (default: 1000)
  # row_limit = 1000
